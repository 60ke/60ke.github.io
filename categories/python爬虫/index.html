<!doctype html><html lang=zh-cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer-when-downgrade"><title>python爬虫 | LookForAdmin的博客</title><meta property="og:title" content="python爬虫 - LookForAdmin的博客"><meta property="og:type" content="article"><meta name=Keywords content="golang,go语言,go语言笔记,LookForAdmin,Rust,分布式,Python,公众号"><meta name=description content="python爬虫"><meta name=author content="LookForAdmin"><meta property="og:url" content="https://60ke.github.io/categories/python%E7%88%AC%E8%99%AB/"><link rel="shortcut icon" href=/favicon.ico type=image/x-icon><link rel=stylesheet href=/css/normalize.css><link rel=stylesheet href=/css/style.css><link rel=alternate type=application/rss+xml href=https://60ke.github.io/categories/python%E7%88%AC%E8%99%AB/index.xml title=LookForAdmin的博客><script type=text/javascript src=//cdn.bootcdn.net/ajax/libs/jquery/3.4.1/jquery.min.js></script>
<link rel=stylesheet href=/css/douban.css><link rel=stylesheet href=/css/other.css></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><a id=logo href=https://60ke.github.io>LookForAdmin的博客</a><p class=description>专注于Golang、Python、Rust、分布式存储</p></div><div><nav id=nav-menu class=clearfix><a href=https://60ke.github.io>首页</a>
<a href=https://60ke.github.io/drafts/ title=草稿箱>草稿箱</a>
<a href=https://60ke.github.io/archives/ title=归档>归档</a>
<a href=https://60ke.github.io/about/ title=关于>关于</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><h3 class=archive-title>分类
<span class=keyword>python爬虫</span>
中的文章</h3><article class=post><header><h1 class=post-title><a href=https://60ke.github.io/drafts/requests%E4%B8%AD%E9%81%87%E5%88%B0%E7%9A%84%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98/>requests中遇到的一些问题</a></h1></header><date class="post-meta meta-date">2018年8月1日</date><div class="post-meta meta-category">|
<a href=/categories/python%E7%88%AC%E8%99%AB>python爬虫</a></div><div class=post-content>今天使用Python的requests模拟posts时总是,无法获取到正确的结果,后来使用postman的时候,在发送请求的时候在body中奖数据类型由默认的Text改为json可以成功,但是使用postman生成的python代码,并加入了正确的cookie还是不能获得正常的返……<p class=readmore><a href=https://60ke.github.io/drafts/requests%E4%B8%AD%E9%81%87%E5%88%B0%E7%9A%84%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98/>阅读全文</a></p></div></article><article class=post><header><h1 class=post-title><a href=https://60ke.github.io/drafts/%E5%BE%AE%E5%8D%9A%E6%90%9C%E7%B4%A2%E7%88%AC%E8%99%AB/>微博搜索爬虫</a></h1></header><date class="post-meta meta-date">2018年7月5日</date><div class="post-meta meta-category">|
<a href=/categories/python%E7%88%AC%E8%99%AB>python爬虫</a></div><div class=post-content>爬虫包括了登录,验证码验证模块 代码放到github上了微博搜索爬虫……<p class=readmore><a href=https://60ke.github.io/drafts/%E5%BE%AE%E5%8D%9A%E6%90%9C%E7%B4%A2%E7%88%AC%E8%99%AB/>阅读全文</a></p></div></article><article class=post><header><h1 class=post-title><a href=https://60ke.github.io/drafts/scrapy%E4%B9%8BFormRequest%E6%A8%A1%E6%8B%9Fpost%E8%AF%B7%E6%B1%82/>scrapy之FormRequest模拟post请求</a></h1></header><date class="post-meta meta-date">2018年1月2日</date><div class="post-meta meta-category">|
<a href=/categories/python%E7%88%AC%E8%99%AB>python爬虫</a></div><div class=post-content>先放代码吧,以后闲了再完善 def start_requests(self): url = "http://www.hebzx.gov.cn/specialnews.aspx?meetingtype=009001" yield scrapy.Request(url,callback=self.parse0) def parse0(self,response): formdata = {"__EVENTTARGET":"AspNetPager1","__EVENTARGUMENT":"2"} return scrapy.FormRequest.from_response( response, formdata=formdata, callback=self.parse1 ) def parse1(self,response): print("1111111111111") print(response.text)……<p class=readmore><a href=https://60ke.github.io/drafts/scrapy%E4%B9%8BFormRequest%E6%A8%A1%E6%8B%9Fpost%E8%AF%B7%E6%B1%82/>阅读全文</a></p></div></article><article class=post><header><h1 class=post-title><a href=https://60ke.github.io/drafts/scrapy%E4%BF%9D%E5%AD%98%E6%95%B0%E6%8D%AE%E4%B8%BA%E5%A4%9A%E4%B8%AAjson/>scrapy保存数据为多个json</a></h1></header><date class="post-meta meta-date">2017年8月23日</date><div class="post-meta meta-category">|
<a href=/categories/python%E7%88%AC%E8%99%AB>python爬虫</a></div><div class=post-content>定义pipline： # -*- coding: utf-8 -*- # Define your item pipelines here # # Don't forget to add your pipeline to the ITEM_PIPELINES setting # See: http://doc.scrapy.org/en/latest/topics/item-pipeline.html # class VmwarePipeline(object): # def process_item(self, item, spider): # return item import json import codecs class VmwarePipeline(object): def process_item(self, item, spider): self.file = codecs.open('%s.json'%item['vid'], 'w', encoding='utf-8') line = json.dumps(dict(item), ensure_ascii=False) + "\n" self.file.write(line) return item def spider_closed(self, spider): self.file.close() PS：scrapy中spiders的解析不能执行的问题 目前为止遇到的情况有两种 解析函数本身存在问题,解析错误导致不能继续传递 解析的……<p class=readmore><a href=https://60ke.github.io/drafts/scrapy%E4%BF%9D%E5%AD%98%E6%95%B0%E6%8D%AE%E4%B8%BA%E5%A4%9A%E4%B8%AAjson/>阅读全文</a></p></div></article><article class=post><header><h1 class=post-title><a href=https://60ke.github.io/drafts/scrapy%E4%B9%8B%E8%8E%B7%E5%8F%96ubuntu%E5%AE%89%E5%85%A8%E5%85%AC%E5%91%8A%E5%B9%B6%E5%B0%86cve%E5%AD%98%E5%82%A8%E4%B8%BAjson/>scrapy之获取ubuntu安全公告,并将cve存储为json</a></h1></header><date class="post-meta meta-date">2017年8月22日</date><div class="post-meta meta-category">|
<a href=/categories/python%E7%88%AC%E8%99%AB>python爬虫</a></div><div class=post-content>创建ubuntu项目 scrapy startproject ubuntu 创建spider模板 cd ubuntu scrapy genspider Ubuntu https://usn.ubuntu.com cat ubuntu/ubuntu/spiders/Ubuntu.py # -*- coding: utf-8 -*- import scrapy class UbuntuSpider(scrapy.Spider): name = 'Ubuntu' allowed_domains = ['https://usn.ubuntu.com'] start_urls = ['http://https://usn.ubuntu.com/'] def parse(self, response): pass ~ 编写spider # -*- coding: utf-8 -*- import scrapy from bs4 import BeautifulSoup import re import requests from ubuntu.items import UbuntuItem class UbuntuSpider(scrapy.Spider): name = 'Ubuntu' allowed_domains = ['usn.ubuntu.com'] def start_requests(self): url = "https://usn.ubuntu.com/usn/" content = requests.get(url).text soup = BeautifulSoup(content,"html.parser") page = soup.find(attrs={"class":"right"}).text.strip() max_page = re.findall("Showing page 1 of (.+?) ",page)[0] start_urls = [] for page in range(int(max_page)): page +=1 url = 'https://usn.ubuntu.com/usn/?page=%s'%page yield scrapy.Request(url,callback=self.parse0) def parse0(self, response): # 获取公告中usn的cv……<p class=readmore><a href=https://60ke.github.io/drafts/scrapy%E4%B9%8B%E8%8E%B7%E5%8F%96ubuntu%E5%AE%89%E5%85%A8%E5%85%AC%E5%91%8A%E5%B9%B6%E5%B0%86cve%E5%AD%98%E5%82%A8%E4%B8%BAjson/>阅读全文</a></p></div></article><article class=post><header><h1 class=post-title><a href=https://60ke.github.io/drafts/scrapy-xpath%E7%94%A8%E6%B3%95/>scrapy-xpath用法</a></h1></header><date class="post-meta meta-date">2017年8月22日</date><div class="post-meta meta-category">|
<a href=/categories/python%E7%88%AC%E8%99%AB>python爬虫</a></div><div class=post-content><p>转载自http://www.cnblogs.com/huhuuu/p/3701017.html　　
Scrapy是基于python的开源爬虫框架,使用起来也比较方便。具体的官网档：http://doc.scrapy.org/en/latest/</p><p>　　之前以为了解python就可以直接爬网站了,原来还要了解HTML,XML的基本协议,在了解基础以后,在了解下xpath的基础上,再使用正则表达式(python下的re包提供支持)提取一定格式的信息（比如说url）,就比较容易处理网页了。</p><p>　　xpath是Scrapy下快速提取特定信息（如title,head,href等）的一个接口。</p>……<p class=readmore><a href=https://60ke.github.io/drafts/scrapy-xpath%E7%94%A8%E6%B3%95/>阅读全文</a></p></div></article><article class=post><header><h1 class=post-title><a href=https://60ke.github.io/drafts/python%E7%88%AC%E8%99%AB%E4%B9%8B%E7%BD%91%E9%A1%B5%E8%A7%A3%E6%9E%90/>python爬虫之——网页解析</a></h1></header><date class="post-meta meta-date">2017年8月17日</date><div class="post-meta meta-category">|
<a href=/categories/python%E7%88%AC%E8%99%AB>python爬虫</a></div><div class=post-content>常用的正则 首先导入第三方包 import re 常用的正则函数： re.findall() re.findall()这个函数之前用的已经比较多了,除了以前提到的re.findall("",target)在“”中放入（.+?）来匹配要查找到内容,还可以结合python中 r+“”的特性,来进行正则查找,同时……<p class=readmore><a href=https://60ke.github.io/drafts/python%E7%88%AC%E8%99%AB%E4%B9%8B%E7%BD%91%E9%A1%B5%E8%A7%A3%E6%9E%90/>阅读全文</a></p></div></article><article class=post><header><h1 class=post-title><a href=https://60ke.github.io/drafts/%E7%88%AC%E8%99%AB%E5%85%A5%E9%97%A8%E5%88%B0%E8%BF%9B%E9%98%B6-1--%E4%BF%9D%E5%AD%98%E4%B8%80%E5%BC%A0%E5%9B%BE%E7%89%87/>爬虫入门到进阶-1--保存一张图片</a></h1></header><date class="post-meta meta-date">2017年6月26日</date><div class="post-meta meta-category">|
<a href=/categories/python%E7%88%AC%E8%99%AB>python爬虫</a></div><div class=post-content>……<p class=readmore><a href=https://60ke.github.io/drafts/%E7%88%AC%E8%99%AB%E5%85%A5%E9%97%A8%E5%88%B0%E8%BF%9B%E9%98%B6-1--%E4%BF%9D%E5%AD%98%E4%B8%80%E5%BC%A0%E5%9B%BE%E7%89%87/>阅读全文</a></p></div></article></div><footer id=footer><div>&copy; 2022 <a href=https://60ke.github.io>LookForAdmin的博客 By LookForAdmin</a></div><br><div><div class=github-badge><a href=https://gohugo.io/ target=_black rel=nofollow><span class=badge-subject>Powered by</span><span class="badge-value bg-blue">Hugo</span></a></div><div class=github-badge><a href=https://github.com/flysnow-org/maupassant-hugo target=_black><span class=badge-subject>Theme</span><span class="badge-value bg-yellowgreen">Maupassant</span></a></div></div></footer><a id=rocket href=#top></a>
<script type=text/javascript src="/js/totop.js?v=0.0.0" async></script>
<script type=text/javascript src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js async></script>
<script src=/js/douban.js></script></div><div id=secondary><section class=widget><form id=search action=https://60ke.github.io/search/ method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=Search>
<input type=hidden name=sitesearch value=https://60ke.github.io>
<button type=submit class="submit icon-search"></button></form></section><section class=widget><h3 class=widget-title>最近文章</h3><ul class=widget-list><li><a href=https://60ke.github.io/posts/%E4%BB%BB%E5%8A%A1%E8%AE%A1%E5%88%92/ title=任务计划>任务计划</a></li><li><a href=https://60ke.github.io/posts/%E6%B5%85%E8%B0%88%E5%85%B1%E8%AF%86%E5%8D%8F%E8%AE%AE/ title=浅谈共识协议>浅谈共识协议</a></li><li><a href=https://60ke.github.io/posts/p2pHolePunching/ title=P2pHolePunching>P2pHolePunching</a></li><li><a href=https://60ke.github.io/posts/go%E6%B3%9B%E5%9E%8B%E5%AE%9E%E8%B7%B5/ title=go泛型实践>go泛型实践</a></li><li><a href=https://60ke.github.io/posts/antlr4/ title="write a antlr4 visitor with golang">write a antlr4 visitor with golang</a></li><li><a href=https://60ke.github.io/posts/%E9%AB%98%E6%80%A7%E8%83%BDweb%E6%9C%8D%E5%8A%A1%E4%B8%8E%E5%B9%B6%E5%8F%91%E6%B5%8B%E8%AF%95/ title=高性能web服务与并发测试>高性能web服务与并发测试</a></li><li><a href=https://60ke.github.io/posts/ewasm%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%BC%80%E5%8F%91/ title=ewasm虚拟机开发>ewasm虚拟机开发</a></li><li><a href=https://60ke.github.io/posts/Enclave%E5%BC%80%E5%8F%91/ title=Enclave开发>Enclave开发</a></li><li><a href=https://60ke.github.io/posts/sgx/ title=sgx开发>sgx开发</a></li></ul></section><section class=widget><h3 class=widget-title><a href=/categories/>分类</a></h3><ul class=widget-list><li><a href=https://60ke.github.io/categories/Linux/>Linux (1)</a></li><li><a href=https://60ke.github.io/categories/mac/>mac (2)</a></li><li><a href=https://60ke.github.io/categories/MySQL/>MySQL (2)</a></li><li><a href=https://60ke.github.io/categories/default/>default (11)</a></li><li><a href=https://60ke.github.io/categories/go/>go (2)</a></li><li><a href=https://60ke.github.io/categories/hexo/>hexo (1)</a></li><li><a href=https://60ke.github.io/categories/Linux/>Linux (1)</a></li><li><a href=https://60ke.github.io/categories/mac/>mac (2)</a></li><li><a href=https://60ke.github.io/categories/old/>old (3)</a></li><li><a href=https://60ke.github.io/categories/others/>others (12)</a></li><li><a href=https://60ke.github.io/categories/php/>php (6)</a></li><li><a href=https://60ke.github.io/categories/python/>python (19)</a></li><li><a href=https://60ke.github.io/categories/python%E7%88%AC%E8%99%AB/>python爬虫 (8)</a></li><li><a href=https://60ke.github.io/categories/rust/>rust (8)</a></li><li><a href=https://60ke.github.io/categories/shell/>shell (1)</a></li><li><a href=https://60ke.github.io/categories/wasm/>wasm (1)</a></li><li><a href=https://60ke.github.io/categories/%E5%A5%B9/>她 (1)</a></li><li><a href=https://60ke.github.io/categories/%E6%9D%82%E7%BB%AA/>杂绪 (3)</a></li></ul></section><section class=widget><h3 class=widget-title><a href=/tags/>标签</a></h3><div class=tagcloud><a href=https://60ke.github.io/tags/blog/>blog</a>
<a href=https://60ke.github.io/tags/c/>c</a>
<a href=https://60ke.github.io/tags/emacs/>emacs</a>
<a href=https://60ke.github.io/tags/english/>english</a>
<a href=https://60ke.github.io/tags/go/>go</a>
<a href=https://60ke.github.io/tags/golang/>golang</a>
<a href=https://60ke.github.io/tags/go%E6%B1%87%E7%BC%96/>go汇编</a>
<a href=https://60ke.github.io/tags/homebrew/>homebrew</a>
<a href=https://60ke.github.io/tags/ios/>ios</a>
<a href=https://60ke.github.io/tags/linux/>linux</a>
<a href=https://60ke.github.io/tags/lisp/>lisp</a>
<a href=https://60ke.github.io/tags/mac/>mac</a>
<a href=https://60ke.github.io/tags/maomaomao/>maomaomao</a>
<a href=https://60ke.github.io/tags/mysql/>mysql</a>
<a href=https://60ke.github.io/tags/other/>other</a>
<a href=https://60ke.github.io/tags/others/>others</a>
<a href=https://60ke.github.io/tags/pycharm/>pycharm</a>
<a href=https://60ke.github.io/tags/python/>python</a>
<a href=https://60ke.github.io/tags/rust/>rust</a>
<a href=https://60ke.github.io/tags/scrapy/>scrapy</a>
<a href=https://60ke.github.io/tags/sgx/>sgx</a>
<a href=https://60ke.github.io/tags/shell/>shell</a>
<a href=https://60ke.github.io/tags/sublime/>sublime</a>
<a href=https://60ke.github.io/tags/vscode/>vscode</a>
<a href=https://60ke.github.io/tags/wasm/>wasm</a>
<a href=https://60ke.github.io/tags/xpath/>xpath</a>
<a href=https://60ke.github.io/tags/%E5%B9%B6%E5%8F%91/>并发</a>
<a href=https://60ke.github.io/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/>并发编程</a>
<a href=https://60ke.github.io/tags/%E5%BC%80%E5%8F%91/>开发</a>
<a href=https://60ke.github.io/tags/%E6%80%BB%E7%BB%93/>总结</a>
<a href=https://60ke.github.io/tags/%E6%AD%A3%E5%88%99/>正则</a>
<a href=https://60ke.github.io/tags/%E6%B3%9B%E5%9E%8B/>泛型</a>
<a href=https://60ke.github.io/tags/%E7%88%AC%E8%99%AB/>爬虫</a>
<a href=https://60ke.github.io/tags/%E7%AC%94%E8%AE%B0/>笔记</a>
<a href=https://60ke.github.io/tags/%E8%B7%A8%E5%B9%B3%E5%8F%B0/>跨平台</a>
<a href=https://60ke.github.io/tags/%E8%B7%AF%E7%94%B1%E5%99%A8/>路由器</a>
<a href=https://60ke.github.io/tags/%E9%80%86%E5%90%91/>逆向</a></div></section><section class=widget><h3 class=widget-title>友情链接</h3><ul class=widget-list><li><a target=_blank href=https://60ke.github.io/old_blogs/ title=旧文章>旧文章</a></li></ul></section><section class=widget><h3 class=widget-title>其它</h3><ul class=widget-list><li><a href=https://60ke.github.io/index.xml>文章 RSS</a></li></ul></section></div></div></div></div></body></html>